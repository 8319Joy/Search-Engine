{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d52dffa",
   "metadata": {},
   "source": [
    "To create a job search engine for Business Analytics positions in India using Python, you can leverage web scraping techniques along with APIs or job portals like Naukri, LinkedIn, or Indeed. Here's a simple example using BeautifulSoup and requests to scrape job listings from a job portal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa424f",
   "metadata": {},
   "source": [
    "# Step-by-Step Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ce33b",
   "metadata": {},
   "source": [
    "Install Required Libraries: You will need requests for sending HTTP requests and BeautifulSoup for scraping job details from web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc19b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\purnangshu roy\\appdata\\roaming\\python\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82004c06",
   "metadata": {},
   "source": [
    "Example Code for Scraping: Here's a real-time example of scraping job postings from a job portal (like Naukri.com or Indeed).\n",
    "Example Code for Scraping: Here's a real-time example of scraping job postings from a job portal (like Naukri.com or Indeed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cc30bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 0 jobs to jobs.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_job_details(job):\n",
    "    title = job.find('a', class_='title').text.strip()\n",
    "    company = job.find('a', class_='company').text.strip()\n",
    "    location = job.find('span', class_='location').text.strip()\n",
    "    summary = job.find('div', class_='summary').text.strip()\n",
    "    return {'Title': title, 'Company': company, 'Location': location, 'Summary': summary}\n",
    "\n",
    "def scrape_jobs(keyword, location, num_pages=1):\n",
    "    jobs = []\n",
    "    base_url = f'https://www.indeed.com/jobs?q={keyword}&l={location}'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        response = requests.get(base_url + f'&start={page*10}', headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        job_cards = soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "\n",
    "        for job in job_cards:\n",
    "            job_data = extract_job_details(job)\n",
    "            jobs.append(job_data)\n",
    "        \n",
    "    return jobs\n",
    "\n",
    "def save_to_csv(jobs, filename='jobs.csv'):\n",
    "    df = pd.DataFrame(jobs)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f'Saved {len(jobs)} jobs to {filename}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Scraping jobs for Business Analytics in India\n",
    "    job_listings = scrape_jobs('Business Analytics', 'India', num_pages=2)\n",
    "    save_to_csv(job_listings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8462cae",
   "metadata": {},
   "source": [
    "Explanation:Explanation:\n",
    "Step 1: We define a function extract_job_details to extract relevant details (title, company, location, and summary) from a job card.\n",
    "Step 1: We define a function extract_job_details to extract relevant details (title, company, location, and summary) from a job card.\n",
    "Step 2: The function scrape_jobs accepts a job keyword (e.g., \"Business Analytics\") and location (e.g., \"India\"). It sends an HTTP request to Indeed or a similar job portal and parses the response HTML using BeautifulSoup.\n",
    "Step 2: The function scrape_jobs accepts a job keyword (e.g., \"Business Analytics\") and location (e.g., \"India\"). It sends an HTTP request to Indeed or a similar job portal and parses the response HTML using BeautifulSoup.\n",
    "Step 3: The results are stored in a list and saved to a CSV file using save_to_csv.\n",
    "Step 3: The results are stored in a list and saved to a CSV file using save_to_csv.\n",
    "Output:Output:\n",
    "The code will create a CSV file (jobs.csv) containing job titles, companies, locations, and summaries of jobs related to Business Analytics in India.\n",
    "The code will create a CSV file (jobs.csv) containing job titles, companies, locations, and summaries of jobs related to Business Analytics in India.\n",
    "Future Enhancements:\n",
    "Future Enhancements:\n",
    "Use APIs like LinkedIn API for fetching more structured job data.\n",
    "Use APIs like LinkedIn API for fetching more structured job data.\n",
    "Add features like filtering based on salary, experience level, or job type.\n",
    "Add features like filtering based on salary, experience level, or job type.\n",
    "Make sure to check the terms and conditions of the website you are scraping to ensure you are compliant.\n",
    "Make sure to check the terms and conditions of the website you are scraping to ensure you are compliant.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afac49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
